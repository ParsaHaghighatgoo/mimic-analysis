{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:31.351255Z",
     "start_time": "2024-10-13T12:22:30.186618Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from holoviews.plotting.bokeh.styles import alpha\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:58.702097Z",
     "start_time": "2024-10-13T12:22:58.662678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importing csv\n",
    "df = pd.read_csv('extractedMimic.csv')\n"
   ],
   "id": "ad76ac30e8c16779",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:33.687892Z",
     "start_time": "2024-10-13T12:22:33.678639Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "8ee07a81a1656506",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4559 entries, 0 to 4558\n",
      "Columns: 106 entries, icustay_id to crystalloid_bolus\n",
      "dtypes: float64(57), int64(39), object(10)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:34.731726Z",
     "start_time": "2024-10-13T12:22:34.649288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop(df[df['age'] < 18].index, inplace=True)\n",
    "\n",
    "df.describe()"
   ],
   "id": "fa2ef7845ce0eee4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          icustay_id        hadm_id  suspected_infection_time_poe_days  \\\n",
       "count    4555.000000    4555.000000                        4555.000000   \n",
       "mean   250637.474863  149922.364874                           0.084101   \n",
       "std     28759.579721   28710.589841                           0.290748   \n",
       "min    200075.000000  100003.000000                          -0.991076   \n",
       "25%    225575.500000  125404.500000                          -0.075677   \n",
       "50%    250984.000000  149667.000000                           0.034965   \n",
       "75%    275436.000000  175042.500000                           0.157309   \n",
       "max    299998.000000  199962.000000                           0.995139   \n",
       "\n",
       "       positiveculture_poe  blood_culture_positive          age      is_male  \\\n",
       "count          4555.000000             4555.000000  4555.000000  4555.000000   \n",
       "mean              0.136334                0.381339    65.173619     0.565971   \n",
       "std               0.343180                0.485769    17.622075     0.495683   \n",
       "min               0.000000                0.000000    18.020900     0.000000   \n",
       "25%               0.000000                0.000000    53.784850     0.000000   \n",
       "50%               0.000000                0.000000    66.591500     1.000000   \n",
       "75%               0.000000                1.000000    79.540400     1.000000   \n",
       "max               1.000000                1.000000    91.400000     1.000000   \n",
       "\n",
       "        race_white   race_black  race_hispanic  ...  glucose_min1  \\\n",
       "count  4555.000000  4555.000000    4555.000000  ...   4525.000000   \n",
       "mean      0.718771     0.086279       0.032931  ...    111.232044   \n",
       "std       0.449649     0.280806       0.178475  ...     36.773707   \n",
       "min       0.000000     0.000000       0.000000  ...     12.000000   \n",
       "25%       0.000000     0.000000       0.000000  ...     89.000000   \n",
       "50%       1.000000     0.000000       0.000000  ...    106.000000   \n",
       "75%       1.000000     0.000000       0.000000  ...    127.000000   \n",
       "max       1.000000     1.000000       1.000000  ...    480.000000   \n",
       "\n",
       "        glucose_max1   glucose_mean          rrt    subject_id      hadm_id.1  \\\n",
       "count    4525.000000    4525.000000  4555.000000   4555.000000    4555.000000   \n",
       "mean      411.037348     177.261026     0.043469  68174.064105  149922.364874   \n",
       "std     14863.345644    2123.773411     0.203932  18470.812604   28710.589841   \n",
       "min        57.000000      52.444444     0.000000    165.000000  100003.000000   \n",
       "25%       130.000000     112.888889     0.000000  53134.000000  125404.500000   \n",
       "50%       166.000000     134.000000     0.000000  68391.000000  149667.000000   \n",
       "75%       217.000000     165.000000     0.000000  83771.500000  175042.500000   \n",
       "max    999999.000000  142966.857100     1.000000  99982.000000  199962.000000   \n",
       "\n",
       "        icustay_id.1   urineoutput  colloid_bolus  crystalloid_bolus  \n",
       "count    4555.000000   4555.000000     508.000000        3361.000000  \n",
       "mean   250637.474863   1842.618441     382.694882         645.671229  \n",
       "std     28759.579721   1535.550605     134.934798         370.024064  \n",
       "min    200075.000000      0.000000     150.000000         250.000000  \n",
       "25%    225575.500000    897.500000     250.000000         500.000000  \n",
       "50%    250984.000000   1560.000000     500.000000         500.000000  \n",
       "75%    275436.000000   2460.000000     500.000000        1000.000000  \n",
       "max    299998.000000  50515.000000    1000.000000       11000.000000  \n",
       "\n",
       "[8 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>suspected_infection_time_poe_days</th>\n",
       "      <th>positiveculture_poe</th>\n",
       "      <th>blood_culture_positive</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_min1</th>\n",
       "      <th>glucose_max1</th>\n",
       "      <th>glucose_mean</th>\n",
       "      <th>rrt</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id.1</th>\n",
       "      <th>icustay_id.1</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>colloid_bolus</th>\n",
       "      <th>crystalloid_bolus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>3361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250637.474863</td>\n",
       "      <td>149922.364874</td>\n",
       "      <td>0.084101</td>\n",
       "      <td>0.136334</td>\n",
       "      <td>0.381339</td>\n",
       "      <td>65.173619</td>\n",
       "      <td>0.565971</td>\n",
       "      <td>0.718771</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>...</td>\n",
       "      <td>111.232044</td>\n",
       "      <td>411.037348</td>\n",
       "      <td>177.261026</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>68174.064105</td>\n",
       "      <td>149922.364874</td>\n",
       "      <td>250637.474863</td>\n",
       "      <td>1842.618441</td>\n",
       "      <td>382.694882</td>\n",
       "      <td>645.671229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28759.579721</td>\n",
       "      <td>28710.589841</td>\n",
       "      <td>0.290748</td>\n",
       "      <td>0.343180</td>\n",
       "      <td>0.485769</td>\n",
       "      <td>17.622075</td>\n",
       "      <td>0.495683</td>\n",
       "      <td>0.449649</td>\n",
       "      <td>0.280806</td>\n",
       "      <td>0.178475</td>\n",
       "      <td>...</td>\n",
       "      <td>36.773707</td>\n",
       "      <td>14863.345644</td>\n",
       "      <td>2123.773411</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>18470.812604</td>\n",
       "      <td>28710.589841</td>\n",
       "      <td>28759.579721</td>\n",
       "      <td>1535.550605</td>\n",
       "      <td>134.934798</td>\n",
       "      <td>370.024064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200075.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>-0.991076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.020900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>52.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>200075.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>225575.500000</td>\n",
       "      <td>125404.500000</td>\n",
       "      <td>-0.075677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.784850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>112.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53134.000000</td>\n",
       "      <td>125404.500000</td>\n",
       "      <td>225575.500000</td>\n",
       "      <td>897.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250984.000000</td>\n",
       "      <td>149667.000000</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.591500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68391.000000</td>\n",
       "      <td>149667.000000</td>\n",
       "      <td>250984.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275436.000000</td>\n",
       "      <td>175042.500000</td>\n",
       "      <td>0.157309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.540400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83771.500000</td>\n",
       "      <td>175042.500000</td>\n",
       "      <td>275436.000000</td>\n",
       "      <td>2460.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299998.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>142966.857100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99982.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>299998.000000</td>\n",
       "      <td>50515.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 96 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:38.315673Z",
     "start_time": "2024-10-13T12:22:38.312251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df[['urineoutput', 'lactate_min','bun_mean','sysbp_min', 'metastatic_cancer', 'inr_max', 'age', 'sodium_max', 'aniongap_max', 'creatinine_min', 'spo2_mean']]\n",
    "\n",
    "y = df['thirtyday_expire_flag']"
   ],
   "id": "bbb70278be3985b0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:39.001844Z",
     "start_time": "2024-10-13T12:22:38.994988Z"
    }
   },
   "cell_type": "code",
   "source": "X.fillna(X.median(), inplace=True)",
   "id": "9a739f2dfce1aade",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:39.928286Z",
     "start_time": "2024-10-13T12:22:39.923093Z"
    }
   },
   "cell_type": "code",
   "source": "X.isnull().sum()",
   "id": "ea2f8389aeaeed27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urineoutput          0\n",
       "lactate_min          0\n",
       "bun_mean             0\n",
       "sysbp_min            0\n",
       "metastatic_cancer    0\n",
       "inr_max              0\n",
       "age                  0\n",
       "sodium_max           0\n",
       "aniongap_max         0\n",
       "creatinine_min       0\n",
       "spo2_mean            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:41.456071Z",
     "start_time": "2024-10-13T12:22:41.450981Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "ed608fc5d08ad009",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4555, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:22:44.579017Z",
     "start_time": "2024-10-13T12:22:44.573219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ],
   "id": "61e83f548dedd4ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3644, 11)\n",
      "Testing set shape: (911, 11)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ab59290ea01c58d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# -----------------------------------------------------------------------",
   "id": "c21df7211d1ac6cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing Stacking",
   "id": "fdb51c498414821a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T18:42:21.062048Z",
     "start_time": "2024-10-08T18:41:45.622080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    # 'n_estimators': [100],\n",
    "    # 'max_depth': [6],\n",
    "    # 'learning_rate': [0.01, 0.1],\n",
    "    # 'subsample': [1.0],\n",
    "    # 'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "#     'alpha': [0, 0.1, 0.2],  # L1 regularization term\n",
    "#     'lambda': [1, 1.5, 2]    # L2 regularization term\n",
    "    'n_estimators': [100],      # Increased number of trees for better learning\n",
    "    'max_depth': [6],           # Control the depth of trees\n",
    "    'learning_rate': [0.05],    # Reduced learning rate\n",
    "    'subsample': [0.8],         # Control overfitting by using 80% of data for each tree\n",
    "    'colsample_bytree': [0.8]   # Featu\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with a logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.8\n",
    "default_threshold = 0.8  # Set the default threshold to 0.8\n",
    "y_pred_default = (y_probs >= default_threshold).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(f\"Default Threshold ({default_threshold:.1f}):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)"
   ],
   "id": "6e9267702840983d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Default Threshold (0.8):\n",
      "Model Accuracy: 83.97366%\n",
      "Model AUC: 84.09910%\n",
      "Confusion Matrix:\n",
      "[[727   2]\n",
      " [144  38]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       729\n",
      "           1       0.95      0.21      0.34       182\n",
      "\n",
      "    accuracy                           0.84       911\n",
      "   macro avg       0.89      0.60      0.63       911\n",
      "weighted avg       0.86      0.84      0.80       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.21\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 80.79034%\n",
      "Model AUC: 84.09910%\n",
      "Confusion Matrix:\n",
      "[[612 117]\n",
      " [ 58 124]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       729\n",
      "           1       0.51      0.68      0.59       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.71      0.76      0.73       911\n",
      "weighted avg       0.83      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T13:34:53.275656Z",
     "start_time": "2024-10-07T13:27:43.479122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "    'colsample_bytree': [0.8],\n",
    "\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, \n",
    "                           scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "cce40a55d22841cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.40066%\n",
      "Model AUC: 83.84434%\n",
      "Confusion Matrix:\n",
      "[[707  22]\n",
      " [111  71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       729\n",
      "           1       0.76      0.39      0.52       182\n",
      "\n",
      "    accuracy                           0.85       911\n",
      "   macro avg       0.81      0.68      0.72       911\n",
      "weighted avg       0.84      0.85      0.83       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.22\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 81.11965%\n",
      "Model AUC: 83.84434%\n",
      "Confusion Matrix:\n",
      "[[616 113]\n",
      " [ 59 123]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       729\n",
      "           1       0.52      0.68      0.59       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.72      0.76      0.73       911\n",
      "weighted avg       0.83      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T09:40:14.605022Z",
     "start_time": "2024-10-07T09:33:49.225995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "    'colsample_bytree': [0.8],\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, \n",
    "                           scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "7f6783765274a759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters:\n",
      "{'xgb__colsample_bytree': 0.8, 'xgb__gamma': 0.1, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100, 'xgb__subsample': 0.8}\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.94951%\n",
      "Model AUC: 84.25361%\n",
      "Confusion Matrix:\n",
      "[[710  19]\n",
      " [109  73]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       729\n",
      "           1       0.79      0.40      0.53       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.83      0.69      0.73       911\n",
      "weighted avg       0.85      0.86      0.84       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.19\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 79.69265%\n",
      "Model AUC: 84.25361%\n",
      "Confusion Matrix:\n",
      "[[596 133]\n",
      " [ 52 130]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87       729\n",
      "           1       0.49      0.71      0.58       182\n",
      "\n",
      "    accuracy                           0.80       911\n",
      "   macro avg       0.71      0.77      0.72       911\n",
      "weighted avg       0.83      0.80      0.81       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T13:48:00.766676Z",
     "start_time": "2024-10-07T13:35:27.290734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "    'colsample_bytree': [0.8],\n",
    "\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, \n",
    "                           scoring='roc_auc', cv=9, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "b8ec7b9d821b0e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 12 candidates, totalling 108 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.18112%\n",
      "Model AUC: 84.10136%\n",
      "Confusion Matrix:\n",
      "[[706  23]\n",
      " [112  70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       729\n",
      "           1       0.75      0.38      0.51       182\n",
      "\n",
      "    accuracy                           0.85       911\n",
      "   macro avg       0.81      0.68      0.71       911\n",
      "weighted avg       0.84      0.85      0.83       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.21\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 80.57080%\n",
      "Model AUC: 84.10136%\n",
      "Confusion Matrix:\n",
      "[[607 122]\n",
      " [ 55 127]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87       729\n",
      "           1       0.51      0.70      0.59       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.71      0.77      0.73       911\n",
      "weighted avg       0.84      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:43:09.970125Z",
     "start_time": "2024-10-07T11:28:31.685002Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 12 folds for each of 12 candidates, totalling 144 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.62020%\n",
      "Model AUC: 84.30863%\n",
      "Confusion Matrix:\n",
      "[[710  19]\n",
      " [112  70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92       729\n",
      "           1       0.79      0.38      0.52       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.83      0.68      0.72       911\n",
      "weighted avg       0.85      0.86      0.84       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.22\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 81.22942%\n",
      "Model AUC: 84.30863%\n",
      "Confusion Matrix:\n",
      "[[614 115]\n",
      " [ 56 126]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       729\n",
      "           1       0.52      0.69      0.60       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.72      0.77      0.74       911\n",
      "weighted avg       0.84      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32,
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "    'colsample_bytree': [0.8],\n",
    "\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, \n",
    "                           scoring='roc_auc', cv=12, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "ffd2fa3f2b63b1d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:21:00.084595Z",
     "start_time": "2024-10-13T11:20:59.836853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Train the XGBoost model with hyperparameter tuning\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss', \n",
    "    booster='gbtree', \n",
    "    objective='binary:logistic', \n",
    "    n_estimators=90,      # Increased number of trees for better learning\n",
    "    max_depth=6,           # Control the depth of trees\n",
    "    learning_rate=0.05,    # Reduced learning rate\n",
    "    subsample=0.8,         # Control overfitting by using 80% of data for each tree\n",
    "    colsample_bytree=0.8,   # Feature subsampling\n",
    "    gamma = 0.05,\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)  # Predicted labels (0 or 1)\n",
    "y_probs = xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 3: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Accuracy based on predicted labels\n",
    "auc = roc_auc_score(y_test, y_probs)  # AUC based on predicted probabilities\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)  # Confusion matrix based on predicted labels\n",
    "class_report = classification_report(y_test, y_pred)  # Classification report based on predicted labels\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Model Accuracy: {accuracy * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ],
   "id": "1c15eb23554ea1d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 85.51043%\n",
      "Model AUC: 84.74804%\n",
      "Confusion Matrix:\n",
      "[[712  17]\n",
      " [115  67]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       729\n",
      "           1       0.80      0.37      0.50       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.83      0.67      0.71       911\n",
      "weighted avg       0.85      0.86      0.83       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5dcf834fb60ff845"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
