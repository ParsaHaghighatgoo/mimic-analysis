{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T06:06:59.470977Z",
     "start_time": "2024-12-09T06:06:55.345500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "fcb301b4e4cf4505",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:42.681663Z",
     "start_time": "2024-10-07T06:02:42.643284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# importing csv\n",
    "df = pd.read_csv('extractedMimic.csv')\n"
   ],
   "id": "881f3e186c927c8e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:45.218398Z",
     "start_time": "2024-10-07T06:02:45.211427Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "5a21894e3e134e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4559 entries, 0 to 4558\n",
      "Columns: 106 entries, icustay_id to crystalloid_bolus\n",
      "dtypes: float64(57), int64(39), object(10)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:46.368232Z",
     "start_time": "2024-10-07T06:02:46.356097Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "82d8826242d113d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   icustay_id  hadm_id              intime             outtime    dbsource  \\\n",
       "0      205941   156324  28/5/2157 14:26:21  30/5/2157 14:18:24  metavision   \n",
       "1      252848   163315  29/7/2196 02:26:17  29/7/2196 12:02:39  metavision   \n",
       "2      237901   180937  14/2/2145 17:55:07  23/2/2145 12:43:43  metavision   \n",
       "3      207491   143962  11/6/2159 12:47:02  14/6/2159 16:31:30  metavision   \n",
       "4      293063   118489   1/1/2135 17:28:33   2/1/2135 06:56:56  metavision   \n",
       "\n",
       "  suspected_infection_time_poe  suspected_infection_time_poe_days  \\\n",
       "0           28/5/2157 15:30:00                          -0.044201   \n",
       "1           29/7/2196 04:57:00                          -0.104664   \n",
       "2           14/2/2145 21:20:00                          -0.142280   \n",
       "3           11/6/2159 12:11:00                           0.025023   \n",
       "4            1/1/2135 15:55:00                           0.064965   \n",
       "\n",
       "    specimen_poe  positiveculture_poe antibiotic_time_poe  ... glucose_min1  \\\n",
       "0    MRSA SCREEN                    0  28/5/2157 00:00:00  ...         40.0   \n",
       "1    MRSA SCREEN                    1  29/7/2196 00:00:00  ...        182.0   \n",
       "2  BLOOD CULTURE                    0  15/2/2145 00:00:00  ...        123.0   \n",
       "3  BLOOD CULTURE                    0  11/6/2159 00:00:00  ...         92.0   \n",
       "4  BLOOD CULTURE                    0   1/1/2135 00:00:00  ...        150.0   \n",
       "\n",
       "   glucose_max1  glucose_mean rrt  subject_id hadm_id.1  icustay_id.1  \\\n",
       "0         202.0     87.250000   0       88883    156324        205941   \n",
       "1         231.0    206.500000   0       46154    163315        252848   \n",
       "2         185.0    151.285714   1       42682    180937        237901   \n",
       "3         118.0    105.000000   0       45111    143962        207491   \n",
       "4         163.0    155.000000   0       56648    118489        293063   \n",
       "\n",
       "   urineoutput  colloid_bolus  crystalloid_bolus  \n",
       "0          0.0            NaN              250.0  \n",
       "1          0.0            NaN              250.0  \n",
       "2          0.0            NaN              250.0  \n",
       "3          4.0            NaN              250.0  \n",
       "4          5.0            NaN              250.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>dbsource</th>\n",
       "      <th>suspected_infection_time_poe</th>\n",
       "      <th>suspected_infection_time_poe_days</th>\n",
       "      <th>specimen_poe</th>\n",
       "      <th>positiveculture_poe</th>\n",
       "      <th>antibiotic_time_poe</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_min1</th>\n",
       "      <th>glucose_max1</th>\n",
       "      <th>glucose_mean</th>\n",
       "      <th>rrt</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id.1</th>\n",
       "      <th>icustay_id.1</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>colloid_bolus</th>\n",
       "      <th>crystalloid_bolus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205941</td>\n",
       "      <td>156324</td>\n",
       "      <td>28/5/2157 14:26:21</td>\n",
       "      <td>30/5/2157 14:18:24</td>\n",
       "      <td>metavision</td>\n",
       "      <td>28/5/2157 15:30:00</td>\n",
       "      <td>-0.044201</td>\n",
       "      <td>MRSA SCREEN</td>\n",
       "      <td>0</td>\n",
       "      <td>28/5/2157 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>87.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>88883</td>\n",
       "      <td>156324</td>\n",
       "      <td>205941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252848</td>\n",
       "      <td>163315</td>\n",
       "      <td>29/7/2196 02:26:17</td>\n",
       "      <td>29/7/2196 12:02:39</td>\n",
       "      <td>metavision</td>\n",
       "      <td>29/7/2196 04:57:00</td>\n",
       "      <td>-0.104664</td>\n",
       "      <td>MRSA SCREEN</td>\n",
       "      <td>1</td>\n",
       "      <td>29/7/2196 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>182.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>206.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>46154</td>\n",
       "      <td>163315</td>\n",
       "      <td>252848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237901</td>\n",
       "      <td>180937</td>\n",
       "      <td>14/2/2145 17:55:07</td>\n",
       "      <td>23/2/2145 12:43:43</td>\n",
       "      <td>metavision</td>\n",
       "      <td>14/2/2145 21:20:00</td>\n",
       "      <td>-0.142280</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>15/2/2145 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>151.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>42682</td>\n",
       "      <td>180937</td>\n",
       "      <td>237901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207491</td>\n",
       "      <td>143962</td>\n",
       "      <td>11/6/2159 12:47:02</td>\n",
       "      <td>14/6/2159 16:31:30</td>\n",
       "      <td>metavision</td>\n",
       "      <td>11/6/2159 12:11:00</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>11/6/2159 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>45111</td>\n",
       "      <td>143962</td>\n",
       "      <td>207491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293063</td>\n",
       "      <td>118489</td>\n",
       "      <td>1/1/2135 17:28:33</td>\n",
       "      <td>2/1/2135 06:56:56</td>\n",
       "      <td>metavision</td>\n",
       "      <td>1/1/2135 15:55:00</td>\n",
       "      <td>0.064965</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2135 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>56648</td>\n",
       "      <td>118489</td>\n",
       "      <td>293063</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:47.719797Z",
     "start_time": "2024-10-07T06:02:47.657784Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe()",
   "id": "2fa97436030e7c6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          icustay_id        hadm_id  suspected_infection_time_poe_days  \\\n",
       "count    4559.000000    4559.000000                        4559.000000   \n",
       "mean   250659.192367  149895.166265                           0.083937   \n",
       "std     28770.209912   28713.760695                           0.290735   \n",
       "min    200075.000000  100003.000000                          -0.991076   \n",
       "25%    225575.500000  125389.000000                          -0.075961   \n",
       "50%    251008.000000  149643.000000                           0.034861   \n",
       "75%    275526.000000  175033.000000                           0.157309   \n",
       "max    299998.000000  199962.000000                           0.995139   \n",
       "\n",
       "       positiveculture_poe  blood_culture_positive          age      is_male  \\\n",
       "count          4559.000000             4559.000000  4559.000000  4559.000000   \n",
       "mean              0.136214                0.381005    65.131600     0.566133   \n",
       "std               0.343053                0.485687    17.671337     0.495662   \n",
       "min               0.000000                0.000000    16.783400     0.000000   \n",
       "25%               0.000000                0.000000    53.764350     0.000000   \n",
       "50%               0.000000                0.000000    66.588700     1.000000   \n",
       "75%               0.000000                1.000000    79.525350     1.000000   \n",
       "max               1.000000                1.000000    91.400000     1.000000   \n",
       "\n",
       "        race_white   race_black  race_hispanic  ...  glucose_min1  \\\n",
       "count  4559.000000  4559.000000    4559.000000  ...   4529.000000   \n",
       "mean      0.718579     0.086203       0.033121  ...    111.229852   \n",
       "std       0.449742     0.280695       0.178973  ...     36.762217   \n",
       "min       0.000000     0.000000       0.000000  ...     12.000000   \n",
       "25%       0.000000     0.000000       0.000000  ...     89.000000   \n",
       "50%       1.000000     0.000000       0.000000  ...    106.000000   \n",
       "75%       1.000000     0.000000       0.000000  ...    127.000000   \n",
       "max       1.000000     1.000000       1.000000  ...    480.000000   \n",
       "\n",
       "        glucose_max1   glucose_mean          rrt    subject_id      hadm_id.1  \\\n",
       "count    4529.000000    4529.000000  4559.000000   4559.000000    4559.000000   \n",
       "mean      410.820932     177.224451     0.043650  68163.638737  149895.166265   \n",
       "std     14856.780903    2122.835511     0.204337  18480.543170   28713.760695   \n",
       "min        57.000000      52.444444     0.000000    165.000000  100003.000000   \n",
       "25%       130.000000     113.000000     0.000000  53111.500000  125389.000000   \n",
       "50%       166.000000     134.190476     0.000000  68368.000000  149643.000000   \n",
       "75%       217.000000     165.000000     0.000000  83771.500000  175033.000000   \n",
       "max    999999.000000  142966.857100     1.000000  99982.000000  199962.000000   \n",
       "\n",
       "        icustay_id.1   urineoutput  colloid_bolus  crystalloid_bolus  \n",
       "count    4559.000000   4559.000000     509.000000        3365.000000  \n",
       "mean   250659.192367   1843.328800     382.434185         645.720951  \n",
       "std     28770.209912   1537.356631     134.930173         369.976339  \n",
       "min    200075.000000      0.000000     150.000000         250.000000  \n",
       "25%    225575.500000    897.500000     250.000000         500.000000  \n",
       "50%    251008.000000   1560.000000     500.000000         500.000000  \n",
       "75%    275526.000000   2460.000000     500.000000        1000.000000  \n",
       "max    299998.000000  50515.000000    1000.000000       11000.000000  \n",
       "\n",
       "[8 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>suspected_infection_time_poe_days</th>\n",
       "      <th>positiveculture_poe</th>\n",
       "      <th>blood_culture_positive</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_min1</th>\n",
       "      <th>glucose_max1</th>\n",
       "      <th>glucose_mean</th>\n",
       "      <th>rrt</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id.1</th>\n",
       "      <th>icustay_id.1</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>colloid_bolus</th>\n",
       "      <th>crystalloid_bolus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4529.000000</td>\n",
       "      <td>4529.000000</td>\n",
       "      <td>4529.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>4559.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>3365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250659.192367</td>\n",
       "      <td>149895.166265</td>\n",
       "      <td>0.083937</td>\n",
       "      <td>0.136214</td>\n",
       "      <td>0.381005</td>\n",
       "      <td>65.131600</td>\n",
       "      <td>0.566133</td>\n",
       "      <td>0.718579</td>\n",
       "      <td>0.086203</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>...</td>\n",
       "      <td>111.229852</td>\n",
       "      <td>410.820932</td>\n",
       "      <td>177.224451</td>\n",
       "      <td>0.043650</td>\n",
       "      <td>68163.638737</td>\n",
       "      <td>149895.166265</td>\n",
       "      <td>250659.192367</td>\n",
       "      <td>1843.328800</td>\n",
       "      <td>382.434185</td>\n",
       "      <td>645.720951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28770.209912</td>\n",
       "      <td>28713.760695</td>\n",
       "      <td>0.290735</td>\n",
       "      <td>0.343053</td>\n",
       "      <td>0.485687</td>\n",
       "      <td>17.671337</td>\n",
       "      <td>0.495662</td>\n",
       "      <td>0.449742</td>\n",
       "      <td>0.280695</td>\n",
       "      <td>0.178973</td>\n",
       "      <td>...</td>\n",
       "      <td>36.762217</td>\n",
       "      <td>14856.780903</td>\n",
       "      <td>2122.835511</td>\n",
       "      <td>0.204337</td>\n",
       "      <td>18480.543170</td>\n",
       "      <td>28713.760695</td>\n",
       "      <td>28770.209912</td>\n",
       "      <td>1537.356631</td>\n",
       "      <td>134.930173</td>\n",
       "      <td>369.976339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200075.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>-0.991076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.783400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>52.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>200075.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>225575.500000</td>\n",
       "      <td>125389.000000</td>\n",
       "      <td>-0.075961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.764350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53111.500000</td>\n",
       "      <td>125389.000000</td>\n",
       "      <td>225575.500000</td>\n",
       "      <td>897.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>251008.000000</td>\n",
       "      <td>149643.000000</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.588700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>134.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68368.000000</td>\n",
       "      <td>149643.000000</td>\n",
       "      <td>251008.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275526.000000</td>\n",
       "      <td>175033.000000</td>\n",
       "      <td>0.157309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.525350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83771.500000</td>\n",
       "      <td>175033.000000</td>\n",
       "      <td>275526.000000</td>\n",
       "      <td>2460.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299998.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>142966.857100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99982.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>299998.000000</td>\n",
       "      <td>50515.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 96 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:49.015055Z",
     "start_time": "2024-10-07T06:02:49.011484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = df[df['age'] < 18].shape[0]  # Using .shape to get the row count\n",
    "print(count)\n"
   ],
   "id": "75ceed2c5a9d2b1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:49.961208Z",
     "start_time": "2024-10-07T06:02:49.897466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop(df[df['age'] < 18].index, inplace=True)\n",
    "\n",
    "df.describe()"
   ],
   "id": "4bfe8ac6677bbbdd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          icustay_id        hadm_id  suspected_infection_time_poe_days  \\\n",
       "count    4555.000000    4555.000000                        4555.000000   \n",
       "mean   250637.474863  149922.364874                           0.084101   \n",
       "std     28759.579721   28710.589841                           0.290748   \n",
       "min    200075.000000  100003.000000                          -0.991076   \n",
       "25%    225575.500000  125404.500000                          -0.075677   \n",
       "50%    250984.000000  149667.000000                           0.034965   \n",
       "75%    275436.000000  175042.500000                           0.157309   \n",
       "max    299998.000000  199962.000000                           0.995139   \n",
       "\n",
       "       positiveculture_poe  blood_culture_positive          age      is_male  \\\n",
       "count          4555.000000             4555.000000  4555.000000  4555.000000   \n",
       "mean              0.136334                0.381339    65.173619     0.565971   \n",
       "std               0.343180                0.485769    17.622075     0.495683   \n",
       "min               0.000000                0.000000    18.020900     0.000000   \n",
       "25%               0.000000                0.000000    53.784850     0.000000   \n",
       "50%               0.000000                0.000000    66.591500     1.000000   \n",
       "75%               0.000000                1.000000    79.540400     1.000000   \n",
       "max               1.000000                1.000000    91.400000     1.000000   \n",
       "\n",
       "        race_white   race_black  race_hispanic  ...  glucose_min1  \\\n",
       "count  4555.000000  4555.000000    4555.000000  ...   4525.000000   \n",
       "mean      0.718771     0.086279       0.032931  ...    111.232044   \n",
       "std       0.449649     0.280806       0.178475  ...     36.773707   \n",
       "min       0.000000     0.000000       0.000000  ...     12.000000   \n",
       "25%       0.000000     0.000000       0.000000  ...     89.000000   \n",
       "50%       1.000000     0.000000       0.000000  ...    106.000000   \n",
       "75%       1.000000     0.000000       0.000000  ...    127.000000   \n",
       "max       1.000000     1.000000       1.000000  ...    480.000000   \n",
       "\n",
       "        glucose_max1   glucose_mean          rrt    subject_id      hadm_id.1  \\\n",
       "count    4525.000000    4525.000000  4555.000000   4555.000000    4555.000000   \n",
       "mean      411.037348     177.261026     0.043469  68174.064105  149922.364874   \n",
       "std     14863.345644    2123.773411     0.203932  18470.812604   28710.589841   \n",
       "min        57.000000      52.444444     0.000000    165.000000  100003.000000   \n",
       "25%       130.000000     112.888889     0.000000  53134.000000  125404.500000   \n",
       "50%       166.000000     134.000000     0.000000  68391.000000  149667.000000   \n",
       "75%       217.000000     165.000000     0.000000  83771.500000  175042.500000   \n",
       "max    999999.000000  142966.857100     1.000000  99982.000000  199962.000000   \n",
       "\n",
       "        icustay_id.1   urineoutput  colloid_bolus  crystalloid_bolus  \n",
       "count    4555.000000   4555.000000     508.000000        3361.000000  \n",
       "mean   250637.474863   1842.618441     382.694882         645.671229  \n",
       "std     28759.579721   1535.550605     134.934798         370.024064  \n",
       "min    200075.000000      0.000000     150.000000         250.000000  \n",
       "25%    225575.500000    897.500000     250.000000         500.000000  \n",
       "50%    250984.000000   1560.000000     500.000000         500.000000  \n",
       "75%    275436.000000   2460.000000     500.000000        1000.000000  \n",
       "max    299998.000000  50515.000000    1000.000000       11000.000000  \n",
       "\n",
       "[8 rows x 96 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>suspected_infection_time_poe_days</th>\n",
       "      <th>positiveculture_poe</th>\n",
       "      <th>blood_culture_positive</th>\n",
       "      <th>age</th>\n",
       "      <th>is_male</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_min1</th>\n",
       "      <th>glucose_max1</th>\n",
       "      <th>glucose_mean</th>\n",
       "      <th>rrt</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id.1</th>\n",
       "      <th>icustay_id.1</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>colloid_bolus</th>\n",
       "      <th>crystalloid_bolus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4525.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>4555.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>3361.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250637.474863</td>\n",
       "      <td>149922.364874</td>\n",
       "      <td>0.084101</td>\n",
       "      <td>0.136334</td>\n",
       "      <td>0.381339</td>\n",
       "      <td>65.173619</td>\n",
       "      <td>0.565971</td>\n",
       "      <td>0.718771</td>\n",
       "      <td>0.086279</td>\n",
       "      <td>0.032931</td>\n",
       "      <td>...</td>\n",
       "      <td>111.232044</td>\n",
       "      <td>411.037348</td>\n",
       "      <td>177.261026</td>\n",
       "      <td>0.043469</td>\n",
       "      <td>68174.064105</td>\n",
       "      <td>149922.364874</td>\n",
       "      <td>250637.474863</td>\n",
       "      <td>1842.618441</td>\n",
       "      <td>382.694882</td>\n",
       "      <td>645.671229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28759.579721</td>\n",
       "      <td>28710.589841</td>\n",
       "      <td>0.290748</td>\n",
       "      <td>0.343180</td>\n",
       "      <td>0.485769</td>\n",
       "      <td>17.622075</td>\n",
       "      <td>0.495683</td>\n",
       "      <td>0.449649</td>\n",
       "      <td>0.280806</td>\n",
       "      <td>0.178475</td>\n",
       "      <td>...</td>\n",
       "      <td>36.773707</td>\n",
       "      <td>14863.345644</td>\n",
       "      <td>2123.773411</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>18470.812604</td>\n",
       "      <td>28710.589841</td>\n",
       "      <td>28759.579721</td>\n",
       "      <td>1535.550605</td>\n",
       "      <td>134.934798</td>\n",
       "      <td>370.024064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200075.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>-0.991076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.020900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>52.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>100003.000000</td>\n",
       "      <td>200075.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>225575.500000</td>\n",
       "      <td>125404.500000</td>\n",
       "      <td>-0.075677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.784850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>112.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53134.000000</td>\n",
       "      <td>125404.500000</td>\n",
       "      <td>225575.500000</td>\n",
       "      <td>897.500000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250984.000000</td>\n",
       "      <td>149667.000000</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.591500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68391.000000</td>\n",
       "      <td>149667.000000</td>\n",
       "      <td>250984.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>275436.000000</td>\n",
       "      <td>175042.500000</td>\n",
       "      <td>0.157309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.540400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>83771.500000</td>\n",
       "      <td>175042.500000</td>\n",
       "      <td>275436.000000</td>\n",
       "      <td>2460.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299998.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>142966.857100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99982.000000</td>\n",
       "      <td>199962.000000</td>\n",
       "      <td>299998.000000</td>\n",
       "      <td>50515.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 96 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:51.078110Z",
     "start_time": "2024-10-07T06:02:51.072685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# checking missing values\n",
    "df.isnull().sum()\n"
   ],
   "id": "1040751896dbcd51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icustay_id              0\n",
       "hadm_id                 0\n",
       "intime                  0\n",
       "outtime                 0\n",
       "dbsource                0\n",
       "                     ... \n",
       "hadm_id.1               0\n",
       "icustay_id.1            0\n",
       "urineoutput             0\n",
       "colloid_bolus        4047\n",
       "crystalloid_bolus    1194\n",
       "Length: 106, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:52.054578Z",
     "start_time": "2024-10-07T06:02:52.051250Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "d77c5d0ff8b01274",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4555, 106)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:52.773807Z",
     "start_time": "2024-10-07T06:02:52.770477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df[['urineoutput', 'lactate_min','bun_mean','sysbp_min', 'metastatic_cancer', 'inr_max', 'age', 'sodium_max', 'aniongap_max', 'creatinine_min', 'spo2_mean']]\n",
    "\n",
    "y = df['thirtyday_expire_flag']"
   ],
   "id": "afb491198ca09fdf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:53.713100Z",
     "start_time": "2024-10-07T06:02:53.705761Z"
    }
   },
   "cell_type": "code",
   "source": "X.head()",
   "id": "2380f31be7deed59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   urineoutput  lactate_min  bun_mean  sysbp_min  metastatic_cancer  inr_max  \\\n",
       "0          0.0          7.0      62.0       78.0                  0      2.4   \n",
       "1          0.0          3.8      27.0       36.0                  0      1.4   \n",
       "2          0.0          1.7      19.5       45.0                  0      1.4   \n",
       "3          4.0          0.8      56.5       78.0                  0      1.2   \n",
       "4          5.0          4.1      32.0       75.0                  0      2.1   \n",
       "\n",
       "       age  sodium_max  aniongap_max  creatinine_min  spo2_mean  \n",
       "0  80.5274         132          27.0             3.0  95.275862  \n",
       "1  91.4000         137          16.0             1.8        NaN  \n",
       "2  80.9409         141          23.0             2.3  98.100000  \n",
       "3  84.8807         141          19.0             4.3  97.600000  \n",
       "4  73.8195         136          24.0             2.2  96.250000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>lactate_min</th>\n",
       "      <th>bun_mean</th>\n",
       "      <th>sysbp_min</th>\n",
       "      <th>metastatic_cancer</th>\n",
       "      <th>inr_max</th>\n",
       "      <th>age</th>\n",
       "      <th>sodium_max</th>\n",
       "      <th>aniongap_max</th>\n",
       "      <th>creatinine_min</th>\n",
       "      <th>spo2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>80.5274</td>\n",
       "      <td>132</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>91.4000</td>\n",
       "      <td>137</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>80.9409</td>\n",
       "      <td>141</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>98.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>56.5</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>84.8807</td>\n",
       "      <td>141</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>97.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>73.8195</td>\n",
       "      <td>136</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>96.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:54.655382Z",
     "start_time": "2024-10-07T06:02:54.650103Z"
    }
   },
   "cell_type": "code",
   "source": "X.isnull().sum()",
   "id": "e89cd0e4abac2891",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urineoutput            0\n",
       "lactate_min            0\n",
       "bun_mean               0\n",
       "sysbp_min              8\n",
       "metastatic_cancer      0\n",
       "inr_max              270\n",
       "age                    0\n",
       "sodium_max             0\n",
       "aniongap_max          14\n",
       "creatinine_min         2\n",
       "spo2_mean              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:55.443716Z",
     "start_time": "2024-10-07T06:02:55.440047Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "bee5dc8801cf7732",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4555, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:56.396783Z",
     "start_time": "2024-10-07T06:02:56.390221Z"
    }
   },
   "cell_type": "code",
   "source": "X.fillna(X.median(), inplace=True)",
   "id": "534c7fc1f129c6bb",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:57.208779Z",
     "start_time": "2024-10-07T06:02:57.204402Z"
    }
   },
   "cell_type": "code",
   "source": "X.isnull().sum()",
   "id": "9c6f74c06b491565",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urineoutput          0\n",
       "lactate_min          0\n",
       "bun_mean             0\n",
       "sysbp_min            0\n",
       "metastatic_cancer    0\n",
       "inr_max              0\n",
       "age                  0\n",
       "sodium_max           0\n",
       "aniongap_max         0\n",
       "creatinine_min       0\n",
       "spo2_mean            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:58.080158Z",
     "start_time": "2024-10-07T06:02:58.076018Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "9c8efc38be4b293",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4555, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:02:59.290889Z",
     "start_time": "2024-10-07T06:02:59.285722Z"
    }
   },
   "cell_type": "code",
   "source": "X.info()",
   "id": "c004b7cab24334c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4555 entries, 0 to 4558\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   urineoutput        4555 non-null   float64\n",
      " 1   lactate_min        4555 non-null   float64\n",
      " 2   bun_mean           4555 non-null   float64\n",
      " 3   sysbp_min          4555 non-null   float64\n",
      " 4   metastatic_cancer  4555 non-null   int64  \n",
      " 5   inr_max            4555 non-null   float64\n",
      " 6   age                4555 non-null   float64\n",
      " 7   sodium_max         4555 non-null   int64  \n",
      " 8   aniongap_max       4555 non-null   float64\n",
      " 9   creatinine_min     4555 non-null   float64\n",
      " 10  spo2_mean          4555 non-null   float64\n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 427.0 KB\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:03:00.241065Z",
     "start_time": "2024-10-07T06:03:00.236453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ],
   "id": "9861ce4652e66f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3644, 11)\n",
      "Testing set shape: (911, 11)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# -------------------------------------------------",
   "id": "f977233eec430620"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply XGBoost",
   "id": "a72adb912cc1257a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:03:09.928866Z",
     "start_time": "2024-10-07T06:03:09.486369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic', n_estimators=200)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)  # Predicted labels (0 or 1)\n",
    "y_probs = xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 3: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Accuracy based on predicted labels\n",
    "auc = roc_auc_score(y_test, y_probs)  # AUC based on predicted probabilities\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)  # Confusion matrix based on predicted labels\n",
    "class_report = classification_report(y_test, y_pred)  # Classification report based on predicted labels\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Model Accuracy: {accuracy * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ],
   "id": "8feae7f1edc9bacf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 83.64435%\n",
      "Model AUC: 79.59194%\n",
      "Confusion Matrix:\n",
      "[[689  40]\n",
      " [109  73]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       729\n",
      "           1       0.65      0.40      0.49       182\n",
      "\n",
      "    accuracy                           0.84       911\n",
      "   macro avg       0.75      0.67      0.70       911\n",
      "weighted avg       0.82      0.84      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# -----------------------------------------------------------------------",
   "id": "87ff922a444ec24d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter Turing",
   "id": "ac8cc40e998c802b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:03:44.929374600Z",
     "start_time": "2024-10-07T06:03:20.674394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]  # Regularization parameter to control overfitting\n",
    "}\n",
    "\n",
    "# Step 2: Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')\n",
    "\n",
    "# Step 3: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 4: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)  # Predicted labels (0 or 1)\n",
    "y_probs = best_xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 6: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Accuracy based on predicted labels\n",
    "auc = roc_auc_score(y_test, y_probs)  # AUC based on predicted probabilities\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)  # Confusion matrix based on predicted labels\n",
    "class_report = classification_report(y_test, y_pred)  # Classification report based on predicted labels\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Model Accuracy: {accuracy * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ],
   "id": "ff6b9a11cd1f8689",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mxgb_model, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Step 4: Fit the model using GridSearchCV\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Best model after hyperparameter tuning\u001B[39;00m\n\u001B[0;32m     20\u001B[0m best_xgb_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    127\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    893\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 895\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[0;32m    899\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\xgboost\\core.py:575\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    574\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1400\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1379\u001B[0m model, metric, params, early_stopping_rounds, callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(\n\u001B[0;32m   1380\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1381\u001B[0m )\n\u001B[0;32m   1382\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1383\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1384\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1397\u001B[0m     enable_categorical\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menable_categorical,\n\u001B[0;32m   1398\u001B[0m )\n\u001B[1;32m-> 1400\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1412\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1414\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[0;32m   1415\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\xgboost\\core.py:575\u001B[0m, in \u001B[0;36m_deprecate_positional_args.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    574\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\xgboost\\training.py:181\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 181\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\xgboost\\core.py:1778\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_features(dtrain)\n\u001B[0;32m   1777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1778\u001B[0m     _check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1779\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1782\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# --------------------------------------------------------------------------------",
   "id": "a9125c5fa02fdd98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# adding Regularization to the code",
   "id": "24cd8996e44c7b11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:32:42.269533Z",
     "start_time": "2024-10-06T11:54:41.946572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter to control overfitting\n",
    "    'alpha': [0, 0.1, 0.2],  # L1 regularization term\n",
    "    'lambda': [1, 1.5, 2]    # L2 regularization term\n",
    "}\n",
    "\n",
    "# Step 2: Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')\n",
    "\n",
    "# Step 3: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 4: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)  # Predicted labels (0 or 1)\n",
    "y_probs = best_xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 6: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Accuracy based on predicted labels\n",
    "auc = roc_auc_score(y_test, y_probs)  # AUC based on predicted probabilities\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)  # Confusion matrix based on predicted labels\n",
    "class_report = classification_report(y_test, y_pred)  # Classification report based on predicted labels\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Model Accuracy: {accuracy * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ],
   "id": "2c6392ad9274c039",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n",
      "Best Parameters: {'alpha': 0, 'gamma': 0.2, 'lambda': 2, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Model Accuracy: 85.62020%\n",
      "Model AUC: 83.77048%\n",
      "Confusion Matrix:\n",
      "[[710  19]\n",
      " [112  70]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.92       729\n",
      "           1       0.79      0.38      0.52       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.83      0.68      0.72       911\n",
      "weighted avg       0.85      0.86      0.84       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# --------------------------------------------------------------------------------",
   "id": "f9df811165df1041"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# adding Threshold Tuning to the code",
   "id": "5c41115601956b7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T11:54:07.886277Z",
     "start_time": "2024-10-06T11:25:09.556001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Define the parameter grid for hyperparameter tuning, including regularization\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "    'alpha': [0, 0.1, 0.2],  # L1 regularization term\n",
    "    'lambda': [1, 1.5, 2]    # L2 regularization term\n",
    "}\n",
    "\n",
    "# Step 2: Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')\n",
    "\n",
    "# Step 3: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 4: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_probs = best_xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 6: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 7: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 8: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "80142b2bd5eb600d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.62020%\n",
      "Model AUC: 83.83153%\n",
      "Confusion Matrix:\n",
      "[[714  15]\n",
      " [116  66]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       729\n",
      "           1       0.81      0.36      0.50       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.84      0.67      0.71       911\n",
      "weighted avg       0.85      0.86      0.83       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.25\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 81.66850%\n",
      "Model AUC: 83.83153%\n",
      "Confusion Matrix:\n",
      "[[619 110]\n",
      " [ 57 125]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88       729\n",
      "           1       0.53      0.69      0.60       182\n",
      "\n",
      "    accuracy                           0.82       911\n",
      "   macro avg       0.72      0.77      0.74       911\n",
      "weighted avg       0.84      0.82      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:10:41.882963Z",
     "start_time": "2024-10-07T06:08:30.798596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [1.0],\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization parameter for tree pruning\n",
    "#     'alpha': [0, 0.1, 0.2],  # L1 regularization term\n",
    "#     'lambda': [1, 1.5, 2]    # L2 regularization term\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with a logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)"
   ],
   "id": "67cf122a11127cb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.94951%\n",
      "Model AUC: 84.24984%\n",
      "Confusion Matrix:\n",
      "[[712  17]\n",
      " [111  71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       729\n",
      "           1       0.81      0.39      0.53       182\n",
      "\n",
      "    accuracy                           0.86       911\n",
      "   macro avg       0.84      0.68      0.72       911\n",
      "weighted avg       0.85      0.86      0.84       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.22\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 80.90011%\n",
      "Model AUC: 84.24984%\n",
      "Confusion Matrix:\n",
      "[[614 115]\n",
      " [ 59 123]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       729\n",
      "           1       0.52      0.68      0.59       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.71      0.76      0.73       911\n",
      "weighted avg       0.83      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T06:54:48.980071Z",
     "start_time": "2024-10-07T06:25:38.892669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Increased number of estimators\n",
    "    'max_depth': [3, 5],  # Slightly deeper trees to allow more complex splits\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Added finer control for learning rate\n",
    "    'subsample': [0.8, 0.9, 1.0],  # Allow models to use less than full data for diversity\n",
    "    'gamma': [0, 0.1],  # Increased regularization options to prevent overfitting\n",
    "#     'alpha': [0, 0.1, 0.3, 0.5],  # Uncomment if you want to explore L1 regularization\n",
    "#     'lambda': [1, 1.5, 2, 2.5]    # Uncomment if you want to explore L2 regularization\n",
    "}\n",
    "\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with a logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)\n"
   ],
   "id": "23c5cc833f100e1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Default Threshold (0.5):\n",
      "Model Accuracy: 85.40066%\n",
      "Model AUC: 84.11643%\n",
      "Confusion Matrix:\n",
      "[[707  22]\n",
      " [111  71]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       729\n",
      "           1       0.76      0.39      0.52       182\n",
      "\n",
      "    accuracy                           0.85       911\n",
      "   macro avg       0.81      0.68      0.72       911\n",
      "weighted avg       0.84      0.85      0.83       911\n",
      "\n",
      "\n",
      "Best Threshold: 0.21\n",
      "Best Threshold Performance:\n",
      "Model Accuracy: 80.68057%\n",
      "Model AUC: 84.11643%\n",
      "Confusion Matrix:\n",
      "[[611 118]\n",
      " [ 58 124]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       729\n",
      "           1       0.51      0.68      0.58       182\n",
      "\n",
      "    accuracy                           0.81       911\n",
      "   macro avg       0.71      0.76      0.73       911\n",
      "weighted avg       0.83      0.81      0.82       911\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T10:23:19.079220600Z",
     "start_time": "2024-10-06T10:17:13.024551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Address class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 2: Calculate scale_pos_weight\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Step 3: Define the model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    booster='gbtree',\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "\n",
    "# Step 4: Set up parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 6, 7],\n",
    "    'min_child_weight': [1, 2, 3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Step 5: Use Stratified K-Folds for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 6: Perform Grid Search with ROC AUC as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='roc_auc', cv=cv, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 7: Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_prob = best_model.predict_proba(X_test)[:, 1]  # Get predicted probabilities for the positive class\n",
    "\n",
    "# Step 8: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_prob)  # Calculate AUC\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Model Accuracy: {accuracy * 100:.5f}%\")\n",
    "print(f\"AUC Score: {auc_score:.5f}\")  # Print AUC\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ],
   "id": "c74f00439e912bb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 36\u001B[0m\n\u001B[0;32m     32\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mxgb_model, param_grid\u001B[38;5;241m=\u001B[39mparam_grid, \n\u001B[0;32m     33\u001B[0m                            scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mroc_auc\u001B[39m\u001B[38;5;124m'\u001B[39m, cv\u001B[38;5;241m=\u001B[39mcv, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_resampled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_resampled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Get the best model from grid search\u001B[39;00m\n\u001B[0;32m     39\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1472\u001B[0m     )\n\u001B[0;32m   1473\u001B[0m ):\n\u001B[1;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    964\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    965\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    966\u001B[0m     )\n\u001B[0;32m    968\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 970\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    974\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1526\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1527\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    908\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    912\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    913\u001B[0m         )\n\u001B[0;32m    914\u001B[0m     )\n\u001B[1;32m--> 916\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    931\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    938\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    939\u001B[0m     )\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1601\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\pythonProject\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1703\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "# Step 1: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [1.0],\n",
    "    'gamma': [0, 0.1, 0.3],  # Regularization parameter for tree pruning\n",
    "#     'alpha': [0, 0.1, 0.2],  # L1 regularization term\n",
    "#     'lambda': [1, 1.5, 2]    # L2 regularization term\n",
    "}\n",
    "\n",
    "# Step 2: Define base models for stacking\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss', booster='gbtree', objective='binary:logistic')),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "\n",
    "# Step 3: Define the stacking classifier with a logistic regression as the final estimator\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Step 4: Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid={'xgb__' + k: v for k, v in param_grid.items()}, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Step 5: Fit the model using GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_stacking_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 6: Make predictions on the test set\n",
    "y_probs = best_stacking_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for class 1\n",
    "\n",
    "# Step 7: Evaluate the model's performance with the default threshold of 0.5\n",
    "y_pred_default = (y_probs >= 0.5).astype(int)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "auc_default = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_default = confusion_matrix(y_test, y_pred_default)\n",
    "class_report_default = classification_report(y_test, y_pred_default)\n",
    "\n",
    "# Print evaluation metrics for the default threshold\n",
    "print(\"Default Threshold (0.5):\")\n",
    "print(f\"Model Accuracy: {accuracy_default * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_default * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_default)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_default)\n",
    "\n",
    "# Step 8: Threshold tuning\n",
    "# Determine the best threshold\n",
    "thresholds = np.arange(0.0, 1.0, 0.01)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Step 9: Evaluate the model's performance with the best threshold\n",
    "y_pred_best = (y_probs >= best_threshold).astype(int)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "auc_best = roc_auc_score(y_test, y_probs)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "# Print evaluation metrics for the best threshold\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f}\")\n",
    "print(\"Best Threshold Performance:\")\n",
    "print(f\"Model Accuracy: {accuracy_best * 100:.5f}%\")\n",
    "print(f\"Model AUC: {auc_best * 100:.5f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_best)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_best)"
   ],
   "id": "1ca6048c01472924"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-05T17:04:16.241934100Z",
     "start_time": "2024-10-05T16:27:49.655933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Define the XGBoost classifier with initial hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, booster='gbtree', objective='binary:logistic')\n",
    "\n",
    "# Step 2: Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],  # Controls the step size (lower = more conservative)\n",
    "    'max_depth': [3, 5, 7, 9],             # Depth of each tree (higher = more complex model)\n",
    "    'n_estimators': [100, 300, 500, 1000],     # Number of boosting rounds (trees)\n",
    "    'subsample': [0.6, 0.8, 1.0],       # Ratio of samples used for training each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0] # Ratio of features used by each tree\n",
    "}\n",
    "\n",
    "# Step 3: Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Step 7: Cross-validation on the entire training set\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%\")\n"
   ],
   "id": "96675e48f0a1b8cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Step 1: Define the XGBoost classifier with initial hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, booster='gbtree', objective='multi:softprob')\n",
    "\n",
    "# Step 2: Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],  # Controls the step size (lower = more conservative)\n",
    "    'max_depth': [3, 5, 7, 9],             # Depth of each tree (higher = more complex model)\n",
    "    'n_estimators': [100, 300, 500, 1000],     # Number of boosting rounds (trees)\n",
    "    'subsample': [0.6, 0.8, 1.0],       # Ratio of samples used for training each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 1.0] # Ratio of features used by each tree\n",
    "}\n",
    "\n",
    "# Step 3: Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Step 5: Make predictions on the test set using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the best hyperparameters and evaluation metrics\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Step 7: Cross-validation on the entire training set\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean() * 100:.2f}%\")\n"
   ],
   "id": "9595a1100f8383e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T09:23:16.898397Z",
     "start_time": "2024-10-05T09:22:00.278614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define features and target variable\n",
    "X = df[['urineoutput', 'lactate_min', 'bun_mean', 'sysbp_min', \n",
    "         'metastatic_cancer', 'inr_max', 'age', 'sodium_max', \n",
    "         'aniongap_max', 'creatinine_min', 'spo2_mean']]\n",
    "y = df['thirtyday_expire_flag']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\"No Expiration\", \"Expiration\"], output_dict=True)\n",
    "\n",
    "# Calculate 95% Confidence Interval using Bootstrapping\n",
    "n_bootstraps = 1000\n",
    "bootstrapped_scores = []\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n",
    "    if len(np.unique(y_test.iloc[indices])) < 2:\n",
    "        continue\n",
    "    score = roc_auc_score(y_test.iloc[indices], y_pred_proba[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "\n",
    "# Confidence intervals\n",
    "lower_bound = np.percentile(bootstrapped_scores, 2.5)\n",
    "upper_bound = np.percentile(bootstrapped_scores, 97.5)\n",
    "\n",
    "# Print the results\n",
    "def print_classification_report(report):\n",
    "    print(\"=== Model Performance Summary ===\")\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"Model AUC: {auc_score:.2f}\")\n",
    "    print(f\"95% Confidence Interval for AUC: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\n=== Detailed Classification Report ===\\n\")\n",
    "\n",
    "    for label, metrics in report.items():\n",
    "        if label in [\"No Expiration\", \"Expiration\"]:\n",
    "            print(f\"Class: {label}\")\n",
    "            print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "            print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "            print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "            print(f\"  Support: {metrics['support']}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"Overall Accuracy: {report['accuracy']:.2f}\")\n",
    "    print(f\"Macro Average Precision: {report['macro avg']['precision']:.2f}\")\n",
    "    print(f\"Macro Average Recall: {report['macro avg']['recall']:.2f}\")\n",
    "    print(f\"Macro Average F1-Score: {report['macro avg']['f1-score']:.2f}\")\n",
    "    print(f\"Weighted Average Precision: {report['weighted avg']['precision']:.2f}\")\n",
    "    print(f\"Weighted Average Recall: {report['weighted avg']['recall']:.2f}\")\n",
    "    print(f\"Weighted Average F1-Score: {report['weighted avg']['f1-score']:.2f}\")\n",
    "\n",
    "    print(\"\\n=== Interpretation ===\")\n",
    "    print(\"The model shows good precision in predicting non-expiration cases, \"\n",
    "          \"but recall for expiration cases indicates room for improvement.\")\n",
    "    print(\"Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\")\n",
    "\n",
    "print_classification_report(class_report)\n"
   ],
   "id": "6bd5af62e9b417f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "=== Model Performance Summary ===\n",
      "Best Hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'subsample': 0.8}\n",
      "Model AUC: 0.83\n",
      "95% Confidence Interval for AUC: [0.79, 0.86]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[710  30]\n",
      " [106  66]]\n",
      "\n",
      "=== Detailed Classification Report ===\n",
      "\n",
      "Class: No Expiration\n",
      "  Precision: 0.87\n",
      "  Recall: 0.96\n",
      "  F1-Score: 0.91\n",
      "  Support: 740.0\n",
      "\n",
      "Class: Expiration\n",
      "  Precision: 0.69\n",
      "  Recall: 0.38\n",
      "  F1-Score: 0.49\n",
      "  Support: 172.0\n",
      "\n",
      "Overall Accuracy: 0.85\n",
      "Macro Average Precision: 0.78\n",
      "Macro Average Recall: 0.67\n",
      "Macro Average F1-Score: 0.70\n",
      "Weighted Average Precision: 0.84\n",
      "Weighted Average Recall: 0.85\n",
      "Weighted Average F1-Score: 0.83\n",
      "\n",
      "=== Interpretation ===\n",
      "The model shows good precision in predicting non-expiration cases, but recall for expiration cases indicates room for improvement.\n",
      "Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T18:40:09.747057Z",
     "start_time": "2024-10-05T18:39:50.957848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Expanded hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\"No Expiration\", \"Expiration\"], output_dict=True)\n",
    "\n",
    "# Calculate 95% Confidence Interval using Bootstrapping\n",
    "n_bootstraps = 1000\n",
    "bootstrapped_scores = []\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n",
    "    if len(np.unique(y_test.iloc[indices])) < 2:\n",
    "        continue\n",
    "    score = roc_auc_score(y_test.iloc[indices], y_pred_proba[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "\n",
    "# Confidence intervals\n",
    "lower_bound = np.percentile(bootstrapped_scores, 2.5)\n",
    "upper_bound = np.percentile(bootstrapped_scores, 97.5)\n",
    "\n",
    "# Print the results\n",
    "def print_classification_report(report):\n",
    "    print(\"=== Model Performance Summary ===\")\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"Model AUC: {auc_score:.3f}\")\n",
    "    print(f\"95% Confidence Interval for AUC: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\n=== Detailed Classification Report ===\\n\")\n",
    "\n",
    "    for label, metrics in report.items():\n",
    "        if label in [\"No Expiration\", \"Expiration\"]:\n",
    "            print(f\"Class: {label}\")\n",
    "            print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "            print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "            print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "            print(f\"  Support: {metrics['support']}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"Overall Accuracy: {report['accuracy']:.3f}\")\n",
    "    print(f\"Macro Average Precision: {report['macro avg']['precision']:.2f}\")\n",
    "    print(f\"Macro Average Recall: {report['macro avg']['recall']:.2f}\")\n",
    "    print(f\"Macro Average F1-Score: {report['macro avg']['f1-score']:.2f}\")\n",
    "    print(f\"Weighted Average Precision: {report['weighted avg']['precision']:.2f}\")\n",
    "    print(f\"Weighted Average Recall: {report['weighted avg']['recall']:.2f}\")\n",
    "    print(f\"Weighted Average F1-Score: {report['weighted avg']['f1-score']:.2f}\")\n",
    "\n",
    "    print(\"\\n=== Interpretation ===\")\n",
    "    print(\"The model shows good precision in predicting non-expiration cases, \"\n",
    "          \"but recall for expiration cases indicates room for improvement.\")\n",
    "    print(\"Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\")\n",
    "\n",
    "print_classification_report(class_report)\n"
   ],
   "id": "34c10baad41318bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "=== Model Performance Summary ===\n",
      "Best Hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
      "Model AUC: 0.835\n",
      "95% Confidence Interval for AUC: [0.80, 0.87]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[711  29]\n",
      " [109  63]]\n",
      "\n",
      "=== Detailed Classification Report ===\n",
      "\n",
      "Class: No Expiration\n",
      "  Precision: 0.87\n",
      "  Recall: 0.96\n",
      "  F1-Score: 0.91\n",
      "  Support: 740.0\n",
      "\n",
      "Class: Expiration\n",
      "  Precision: 0.68\n",
      "  Recall: 0.37\n",
      "  F1-Score: 0.48\n",
      "  Support: 172.0\n",
      "\n",
      "Overall Accuracy: 0.849\n",
      "Macro Average Precision: 0.78\n",
      "Macro Average Recall: 0.66\n",
      "Macro Average F1-Score: 0.69\n",
      "Weighted Average Precision: 0.83\n",
      "Weighted Average Recall: 0.85\n",
      "Weighted Average F1-Score: 0.83\n",
      "\n",
      "=== Interpretation ===\n",
      "The model shows good precision in predicting non-expiration cases, but recall for expiration cases indicates room for improvement.\n",
      "Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T13:37:45.822886Z",
     "start_time": "2024-10-03T13:07:30.117408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define features and target variable\n",
    "X = df[['urineoutput', 'lactate_min', 'bun_mean', 'sysbp_min', \n",
    "         'metastatic_cancer', 'inr_max', 'age', 'sodium_max', \n",
    "         'aniongap_max', 'creatinine_min', 'spo2_mean']]\n",
    "y = df['thirtyday_expire_flag']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Expanded hyperparameter grid for tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],\n",
    "    'subsample': np.linspace(0.5, 1.0, 10),\n",
    "    'colsample_bytree': np.linspace(0.5, 1.0, 10),\n",
    "    'gamma': np.linspace(0, 1, 10),\n",
    "    'alpha': [0, 0.01, 0.1, 1, 10],\n",
    "    'lambda': [0, 0.01, 0.1, 1, 10],\n",
    "    'scale_pos_weight': [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred, target_names=[\"No Expiration\", \"Expiration\"], output_dict=True)\n",
    "\n",
    "# Calculate 95% Confidence Interval using Bootstrapping\n",
    "n_bootstraps = 1000\n",
    "bootstrapped_scores = []\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    indices = rng.randint(0, len(y_pred_proba), len(y_pred_proba))\n",
    "    if len(np.unique(y_test.iloc[indices])) < 2:\n",
    "        continue\n",
    "    score = roc_auc_score(y_test.iloc[indices], y_pred_proba[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "\n",
    "# Confidence intervals\n",
    "lower_bound = np.percentile(bootstrapped_scores, 2.5)\n",
    "upper_bound = np.percentile(bootstrapped_scores, 97.5)\n",
    "\n",
    "# Print the results\n",
    "def print_classification_report(report):\n",
    "    print(\"=== Model Performance Summary ===\")\n",
    "    print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "    print(f\"Model AUC: {auc_score:.2f}\")\n",
    "    print(f\"95% Confidence Interval for AUC: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\n=== Detailed Classification Report ===\\n\")\n",
    "\n",
    "    for label, metrics in report.items():\n",
    "        if label in [\"No Expiration\", \"Expiration\"]:\n",
    "            print(f\"Class: {label}\")\n",
    "            print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "            print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "            print(f\"  F1-Score: {metrics['f1-score']:.2f}\")\n",
    "            print(f\"  Support: {metrics['support']}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"Overall Accuracy: {report['accuracy']:.2f}\")\n",
    "    print(f\"Macro Average Precision: {report['macro avg']['precision']:.2f}\")\n",
    "    print(f\"Macro Average Recall: {report['macro avg']['recall']:.2f}\")\n",
    "    print(f\"Macro Average F1-Score: {report['macro avg']['f1-score']:.2f}\")\n",
    "    print(f\"Weighted Average Precision: {report['weighted avg']['precision']:.2f}\")\n",
    "    print(f\"Weighted Average Recall: {report['weighted avg']['recall']:.2f}\")\n",
    "    print(f\"Weighted Average F1-Score: {report['weighted avg']['f1-score']:.2f}\")\n",
    "\n",
    "    print(\"\\n=== Interpretation ===\")\n",
    "    print(\"The model shows good precision in predicting non-expiration cases, \"\n",
    "          \"but recall for expiration cases indicates room for improvement.\")\n",
    "    print(\"Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\")\n",
    "\n",
    "print_classification_report(class_report)\n"
   ],
   "id": "8fed1ad5e826d3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12288 candidates, totalling 61440 fits\n",
      "=== Model Performance Summary ===\n",
      "Best Hyperparameters: {'colsample_bytree': 0.8, 'gamma': 0.3, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Model AUC: 0.84\n",
      "95% Confidence Interval for AUC: [0.80, 0.87]\n",
      "\n",
      "Confusion Matrix:\n",
      "[[712  28]\n",
      " [104  68]]\n",
      "\n",
      "=== Detailed Classification Report ===\n",
      "\n",
      "Class: No Expiration\n",
      "  Precision: 0.87\n",
      "  Recall: 0.96\n",
      "  F1-Score: 0.92\n",
      "  Support: 740.0\n",
      "\n",
      "Class: Expiration\n",
      "  Precision: 0.71\n",
      "  Recall: 0.40\n",
      "  F1-Score: 0.51\n",
      "  Support: 172.0\n",
      "\n",
      "Overall Accuracy: 0.86\n",
      "Macro Average Precision: 0.79\n",
      "Macro Average Recall: 0.68\n",
      "Macro Average F1-Score: 0.71\n",
      "Weighted Average Precision: 0.84\n",
      "Weighted Average Recall: 0.86\n",
      "Weighted Average F1-Score: 0.84\n",
      "\n",
      "=== Interpretation ===\n",
      "The model shows good precision in predicting non-expiration cases, but recall for expiration cases indicates room for improvement.\n",
      "Consider exploring class weighting or additional feature engineering to improve predictions for the minority class.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6643c8f02d579da6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
